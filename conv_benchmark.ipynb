{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/ccengiz17/.anaconda3/envs/dl_frameworks/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "#import torch.autograd as autograd\n",
    "\n",
    "import numpy as np\n",
    "from mxnetnet import MXNetNet\n",
    "from pytorchnet import PytorchNet\n",
    "from tfnet import TFNet\n",
    "        \n",
    "# bug: filter reshaping possibly causes incorrect results \n",
    "class ConvBenchmark:\n",
    "    def __init__(self, **bench_args):\n",
    "        convweights = bench_args[\"convweights\"]\n",
    "        self.conv_filters_ = []\n",
    "        #filter_ = autograd.Variable(torch.FloatTensor([[[[-1, 1]]]])).numpy()\n",
    "        for w in convweights:\n",
    "            w_array = np.random.random(w).astype(np.float32)\n",
    "            self.conv_filters_.append(w_array)\n",
    "            #self.conv_filters_.append(filter_)\n",
    "        \n",
    "        \n",
    "        if \"poolings\" in bench_args:\n",
    "            self.poolings_ = bench_args[\"poolings\"]\n",
    "        else:\n",
    "            self.poolings_ = False\n",
    "        \n",
    "        self.networks_ = {}\n",
    "        self.networks_[\"pytorchCNN\"] = PytorchNet(self.conv_filters_, self.poolings_)\n",
    "        self.networks_[\"TF_CNN\"] = TFNet(self.conv_filters_, self.poolings_)\n",
    "        self.networks_[\"MXNet_CNN\"] = MXNetNet(self.conv_filters_, self.poolings_)\n",
    "        \n",
    "        self.input_ = np.random.random(bench_args[\"inputsize\"]).astype(np.float32)\n",
    "        self.results_ = {}\n",
    "        \n",
    "    def runNetworks(self):\n",
    "        # Pytorch nn.Conv2d takes input a 4D Tensor of [nSamples x nChannels x Height x Width]\n",
    "        # Input is defined in Pytorch layout fashion\n",
    "        for netname, network in self.networks_.items():\n",
    "            #output, t = network.forward(np.copy(self.input_))\n",
    "            #self.results_[netname] = {\"output\": output, \"runtime\": t}\n",
    "            output, t, conv_filters = network.forward(np.copy(self.input_))\n",
    "            self.results_[netname] = {\"output\": output, \"runtime\": t, \"filters\": conv_filters}\n",
    "\n",
    "            print(\"{} took {:.3} seconds.\".format(netname, t))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is a 4D Tensor of [nSamples x nChannels x Height x Width]\n",
    "inBS, inCh, inHeight, inWidth = (2,1,32,32)\n",
    "inputsize = inBS, inCh, inHeight, inWidth\n",
    "\n",
    "# Filters are 4D tensor in form [out_channels, in_channels, fil_height, fil_width]\n",
    "conv1w = (6, 1, 5, 5)\n",
    "conv2w = (16, 6, 5, 5)\n",
    "convweights = (conv1w, conv2w)\n",
    "\n",
    "poolings = (2,2)\n",
    "\n",
    "benchmark = ConvBenchmark(inputsize=inputsize, convweights=convweights, poolings=poolings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = ConvBenchmark(inputsize=(256,3,32,32), convweights=((512, 3, 3, 3), (1024, 512, 3, 3)), poolings=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "size of x before: torch.Size([256, 3, 32, 32])\n",
      "size of filter : torch.Size([512, 3, 3, 3])\n",
      "size of x after filter: torch.Size([256, 512, 30, 30])\n",
      "size of x after pool: torch.Size([256, 512, 15, 15])\n",
      " \n",
      "layer: 1\n",
      "size of x before: torch.Size([256, 512, 15, 15])\n",
      "size of filter : torch.Size([1024, 512, 3, 3])\n",
      "size of x after filter: torch.Size([256, 1024, 13, 13])\n",
      "size of x after pool: torch.Size([256, 1024, 6, 6])\n",
      " \n",
      "pytorchCNN took 12.6 seconds.\n",
      "layer: 0\n",
      "size of x before: (256, 32, 32, 3)\n",
      "size of filter : (3, 3, 3, 512)\n",
      "size of x after filter: (256, 30, 30, 512)\n",
      "size of x after pool: (256, 15, 15, 512)\n",
      " \n",
      "layer: 1\n",
      "size of x before: (256, 15, 15, 512)\n",
      "size of filter : (3, 3, 512, 1024)\n",
      "size of x after filter: (256, 13, 13, 1024)\n",
      "size of x after pool: (256, 6, 6, 1024)\n",
      " \n",
      "TF_CNN took 0.122 seconds.\n",
      "layer: 0\n",
      "size of x before: (256, 3, 32, 32)\n",
      "size of filter : (512, 3, 3, 3)\n",
      "size of x after filter: (256, 512, 30, 30)\n",
      "size of x after pool: (256, 512, 15, 15)\n",
      " \n",
      "layer: 1\n",
      "size of x before: (256, 512, 15, 15)\n",
      "size of filter : (1024, 512, 3, 3)\n",
      "size of x after filter: (256, 1024, 13, 13)\n",
      "size of x after pool: (256, 1024, 6, 6)\n",
      " \n",
      "MXNet_CNN took 0.0254 seconds.\n"
     ]
    }
   ],
   "source": [
    "benchmark.runNetworks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_out = benchmark.results_[\"pytorchCNN\"][\"output\"]\n",
    "mxnet_out = benchmark.results_[\"MXNet_CNN\"][\"output\"]\n",
    "tf_out = benchmark.results_[\"TF_CNN\"][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1024, 6, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_out.shape)\n",
    "print(type(pytorch_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1024, 6, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(mxnet_out.shape)\n",
    "print(type(mxnet_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1024, 6, 6)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tf_out = tf_out.reshape(pytorch_out.shape)\n",
    "print(tf_out.shape)\n",
    "print(type(tf_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17700.90625   ,  18105.2109375 ,  17949.94140625],\n",
       "       [ 18606.359375  ,  18277.50195312,  17178.41601562],\n",
       "       [ 18592.23828125,  18842.01953125,  17894.95898438]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_out[0,0,0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17700.90625   ,  18105.2109375 ,  17949.94140625],\n",
       "       [ 18606.359375  ,  18277.50195312,  17178.41601562],\n",
       "       [ 18592.23828125,  18842.01953125,  17894.95898438]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxnet_out[0,0,0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17383.02148438,  17229.13867188,  17244.0625    ],\n",
       "       [ 17229.68554688,  17093.66601562,  17100.80859375],\n",
       "       [ 17220.58984375,  17143.87304688,  17195.0546875 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_out[0,0,0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(mxnet_out, pytorch_out, atol=0.001).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "fce54db380b043ad82e6d209f7198b89",
   "lastKernelId": "afbe5286-e74f-468c-8dda-c5567a62122b"
  },
  "kernelspec": {
   "display_name": "Python (dl_frameworks)",
   "language": "python",
   "name": "dl_frameworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
